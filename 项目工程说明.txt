1.Release是用的DIDIVoiceRecognitionClient_Publish.h；

2.ISCForOneProject项目git地址：https://git.xiaojukeji.com/zhangkaiming/ISCForOneProject，是集成中间层和ASR SDK的pod工程，不需要编译，是通过pod导入工程；

3.获取语音音量的接口：[[DIDIVoiceRecognitionClient sharedInstance] getCurrentDBLevelMeter]；

4、DiSpecialDriver项目的服务中心H5为KFOnlineWebViewController，在registBridge方法中调用录音模块，唤起KefuMsgClient类的相关接口，即@“startRecord"（[kefuClient startRecWithPid:data]）与@"endRecord"（[kefuClient finishSpeak]）；

5.[kefuClient startRecWithPid:data]中data的数据结构为
{
    chatInfo =     {
        businessType = 1;
        cell = 18800000004;
        cityId = 1;
        message = "";
        mid = "6220bd3e-f003-4a6b-8f57-64ac0b0afcdc";
        msgType = 0;
        orderId = 0;
        roleType = 3;
        skillType = common;
        source = "-1";
        traceId = "1c9a629d-d982-4139-8e43-24f143931d20";
        uid = 564069099110401;
    };
    pid = 10001;
	newVoice = 0; //1为新版0为旧版
}
凯铭，我看之前司机端把小流量的判断扔到KefuMsgClient里判断了。

6.查看.a静态库支持的CPU型号命令：lipo -info XXX.a
合并模拟器与真机的.a库，命令：
lipo -create XXX/iphoneos/XXX.a XXX/iphonesimulator/XXX.a  -output XXX/iOS/XXX.a
其中XXX/iphoneos/XXX.a为真机库，XXX/iphonesimulator/XXX.a为模拟器库，-output XXX/iOS/XXX.a为两个库合并后存放的路径
lipo -create Release-iphoneos/libDIDIKeFuClient.a Release-iphonesimulator/libDIDIKeFuClient.a -output Release-iOS/libDIDIKeFuClient.a

7.在Demo项目里增加Podfile文件，集成ISCProject库，内容如下：
使用仓库的某个tag:
target 'Waver' do
    platform:ios, '7.0'
    pod 'ISCProject', :git => "git@git.xiaojukeji.com:zhangkaiming/ISCForOneProject.git", :tag => "0.2.1"
end
使用仓库的其他分支:
target 'Waver' do
    platform:ios, '7.0'
    pod 'ISCProject', :git => "git@git.xiaojukeji.com:zhangkaiming/ISCForOneProject.git", :branch => 'develop'
end

8.集成ISCProject库后，编译报错："vtable for __cxxabiv1::__class_type_info", referenced from:
      typeinfo for CAXException in libDDVoiceRecognitionClient.a(DIDIVRDBLevelMeterListener.o)
ld: symbol(s) not found for architecture i386
clang: error: linker command failed with exit code 1 (use -v to see invocation)
解决方案：
遇到这样的问题主要是第三方库导入的配置不对，静态库中采用ObjectC++实现，因此需要您保证您工程中至少有一个.mm后缀的源文件(您可以将任意一个.m后缀的文件改名为.mm)，或者在工程属性中指定编译方式，即将Xcode的Project -> Edit Active Target -> Build -> GCC4.2 - Language -> Compile Sources As设置为"Objective-C++"

9.新版发布流程：编译好新的识别库，增加新UI后把相关头文件和.a库替换到ISCForOneProject工程，push到代码库里，司机端pod update后就可以调；

10.0719在线客服需求疑问
（1）结束录音的交互方式？
（2）录音提示音类型：
开始 iOS:record_start.caf
结束 iOS:record_end.caf
出错 iOS:record_fail.caf
附件是现有的声音文件
（3）点按录音图标到波纹的交互方式？明确H5与Native各自要实现的部分。

11.录音提示音
提示音目录：/Users/guoliting/didichuxing/asr-ios-sdk/ios-sdk/DDASRClientSample/libDDASRClient/DDASRClientResources/Tone
开启提示音：[[DIDIVoiceRecognitionClient sharedInstance] setPlayTone:EVoiceRecognitionPlayTonesRecStart isPlay:YES];
Demo使用时需要将DDASRClientResources文件夹拷贝至项目所在目录，添加至工程时打开Options只勾选Create folder reference，这样Demo运行时的App包里就会包含DDASRClientResources文件夹；

12.语音识别尾点检测
百度Android在线语音识别SDK使用方法  http://blog.csdn.net/voicefans/article/details/27345137
语音活动检测(Voice Activity Detection,VAD)又称语音端点检测,语音边界检测。
#define     PARAM_MAX_SP_DURATION       2  //控制每句之间说话的最大静音时间，单位毫秒
#define     PARAM_SPEECH_END            9  //端点检测超时，单位毫秒
[[DIDIVREncoder sharedInstance] setParameter: PARAM_MAX_SP_DURATION withValue: 2000];
    [[DIDIVREncoder sharedInstance]setParameter:PARAM_SPEECH_END withValue:35];
// DIDIVoiceRecognitionClientResources/Tone
// DDASRClientResources/Tone
static NSString *kRecordTonePath = @"DDASRClientResources/Tone/";

/var/containers/Bundle/Application/E950D322-76C8-404D-8B10-6A3F3F1261DA/DiSpecialDriver.app/DDASRClientResources/Tone/record_start.caf
/var/mobile/Containers/Data/Application/142E3545-B101-4107-A832-E24C707ED962/Documents/RecordVoice/2016_07_29_17_47_37.mp3

收到的结果：{
    "asr_param" =     {
        "err_no" = "-3003";
        error = "get result error";
        idx = 1;
        sid = "2742AADC-AED6-42D5-AAD2-D8D13551AEB2";
    };
}

13.libDDVoiceRecognitionClient.a替换为Debug版，Release版运行异常。 
Thread 4:signal SIGABRT 
Stack buffer overflow detected

static void gen_key(int num, char key[]){
    if (num < 8 || key == NULL) {
        return;
    }
    if (num != 8) {
        num = 8;
    }
    
    char magic[] = "*Xj->aSr";
    
    memset(key, 127, num);
    
    for (int i = 0; i < num; ++i) {
        
        key[i] = abs((key[i] * magic[i]))%95 + 32;
    }
    return;
}
http://123.125.253.3/static/login.html

Today we’re announcing our intention to merge Uber China with Didi Chuxing.


NSBundle *bundle = [NSBundle mainBundle];
    NSString* path = [bundle pathForResource:fileName ofType:KRecordToneFileEx inDirectory:kRecordTonePath];
    NSURL *musicUrl = [[NSURL alloc] initFileURLWithPath:path];
/var/containers/Bundle/Application/54EF45B0-7E31-4134-81C1-04B92A67BF79/DiSpecialDriver.app/DDASRClientResources/Tone/fristVoice.mp3
path:/var/containers/Bundle/Application/54EF45B0-7E31-4134-81C1-04B92A67BF79/DiSpecialDriver.app/DDASRClientResources/Tone/record_start.caf

14.测试地址
NSURL *url = [NSURL URLWithString:item.url];
//    NSURL *url = [NSURL URLWithString:@"http://123.125.253.3/static/login.html"]; //测试H5
2016-08-01 21:09:12.693 DiSpecialDriversDemo[358:40572] App Transport Security has blocked a cleartext HTTP (http://) resource load since it is insecure. Temporary exceptions can be configured via your app's Info.plist file.

15.正常结束  [[DIDIVoiceRecognitionClient sharedInstance] speakFinish];
取消 [[DIDIVoiceRecognitionClient sharedInstance] stopVoiceRecognition];
EVoiceRecognitionClientWorkStatusStart,                  // 检测到用户开始说话
晚于EVoiceRecognitionClientWorkStatusNewRecordData,          // 录音数据回调
