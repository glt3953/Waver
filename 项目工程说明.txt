1.Release是用的DIDIVoiceRecognitionClient_Publish.h；

2.ISCForOneProject项目git地址：https://git.xiaojukeji.com/zhangkaiming/ISCForOneProject，是集成中间层和ASR SDK的pod工程，不需要编译，是通过pod导入工程；

3.获取语音音量的接口：[[DIDIVoiceRecognitionClient sharedInstance] getCurrentDBLevelMeter]；

4、DiSpecialDriver项目的服务中心H5为KFOnlineWebViewController，在registBridge方法中调用录音模块，唤起KefuMsgClient类的相关接口，即@“startRecord"（[kefuClient startRecWithPid:data]）与@"endRecord"（[kefuClient finishSpeak]）；

5.[kefuClient startRecWithPid:data]中data的数据结构为
{
    chatInfo =     {
        businessType = 1;
        cell = 18800000004;
        cityId = 1;
        message = "";
        mid = "6220bd3e-f003-4a6b-8f57-64ac0b0afcdc";
        msgType = 0;
        orderId = 0;
        roleType = 3;
        skillType = common;
        source = "-1";
        traceId = "1c9a629d-d982-4139-8e43-24f143931d20";
        uid = 564069099110401;
    };
    pid = 10001;
	newVoice = 0; //1为新版0为旧版
}
凯铭，我看之前司机端把小流量的判断扔到KefuMsgClient里判断了。

6.查看.a静态库支持的CPU型号命令：lipo -info XXX.a
合并模拟器与真机的.a库，命令：
lipo -create XXX/iphoneos/XXX.a XXX/iphonesimulator/XXX.a  -output XXX/iOS/XXX.a
其中XXX/iphoneos/XXX.a为真机库，XXX/iphonesimulator/XXX.a为模拟器库，-output XXX/iOS/XXX.a为两个库合并后存放的路径

7.在Demo项目里增加Podfile文件，集成ISCProject库，内容如下：
使用仓库的某个tag:
target 'Waver' do
    platform:ios, '7.0'
    pod 'ISCProject', :git => "git@git.xiaojukeji.com:zhangkaiming/ISCForOneProject.git", :tag => "0.2.1"
end
使用仓库的其他分支:
target 'Waver' do
    platform:ios, '7.0'
    pod 'ISCProject', :git => "git@git.xiaojukeji.com:zhangkaiming/ISCForOneProject.git", :branch => 'develop'
end

8.集成ISCProject库后，编译报错："vtable for __cxxabiv1::__class_type_info", referenced from:
      typeinfo for CAXException in libDDVoiceRecognitionClient.a(DIDIVRDBLevelMeterListener.o)
ld: symbol(s) not found for architecture i386
clang: error: linker command failed with exit code 1 (use -v to see invocation)
解决方案：
遇到这样的问题主要是第三方库导入的配置不对，静态库中采用ObjectC++实现，因此需要您保证您工程中至少有一个.mm后缀的源文件(您可以将任意一个.m后缀的文件改名为.mm)，或者在工程属性中指定编译方式，即将Xcode的Project -> Edit Active Target -> Build -> GCC4.2 - Language -> Compile Sources As设置为"Objective-C++"

9.新版发布流程：编译好新的识别库，增加新UI后把相关头文件和.a库替换到ISCForOneProject工程，push到代码库里，司机端pod update后就可以调；

10.0719在线客服需求疑问
（1）结束录音的交互方式？
（2）录音提示音类型：
开始 iOS:record_start.caf
结束 iOS:record_end.caf
出错 iOS:record_fail.caf
附件是现有的声音文件
（3）点按录音图标到波纹的交互方式？明确H5与Native各自要实现的部分。

11.录音提示音
提示音目录：/Users/guoliting/didichuxing/asr-ios-sdk/ios-sdk/DDASRClientSample/libDDASRClient/DDASRClientResources/Tone
开启提示音：[[DIDIVoiceRecognitionClient sharedInstance] setPlayTone:EVoiceRecognitionPlayTonesRecStart isPlay:YES];
Demo使用时需要将DDASRClientResources文件夹拷贝至项目所在目录，添加至工程时打开Options只勾选Create folder reference，这样Demo运行时的App包里就会包含DDASRClientResources文件夹；

12.语音识别尾点检测
语音活动检测(Voice Activity Detection,VAD)又称语音端点检测,语音边界检测。
DDWORD lVADResultStartLoc = 0;          /**< @brief VAD Result Start Loc (Frame) */
DDWORD lVADResultCurLoc = 0;            /**< @brief VAD Result Current Loc (Frame) */
DDWORD lFrameCnt = 0;                   /**< @brief Frame Counter (Last time) */
DDWORD lFrameCntTotal = 0;              /**< @brief For SpeechMode = 1, Total Frame Cnt */
short nIn_Speech_Threshold  = 8;
#define     VAD_FRAMELENGTH             128

DWORD nSampleRate = 8000;
mSampleRate = inSampleRate;
nIn_Speech_Threshold = 8;
short nIn_Speech_Threshold  = 8;
#define BDVR_PCM_SAMPLE_RATE_16K 64000 //用于检测用户未说话的超时时间 16000（8S）64000（2S）

#import "DIDIVREncoder.h"
DIDIVRClientImp
if(self.isCalledRecordEndOperation == NO && self.isUserEnd == NO) // 每次完成只能响应一次
		{
			NSTimeInterval duration = [[NSDate date] timeIntervalSince1970] - self.recordStartTime;
			self.recordLengthSinceUserEnd = (int)(duration * iCurrentSampleRate * 2);
			DIDIVRLogDebug(@"finish record real %f, %ld", duration, (long)self.recordLengthSinceUserEnd);
			self.isUserEnd = YES;
            [self currentTimeRecognitionStatusNotifyObsWithStatus:EVoiceRecognitionClientWorkStatusEnd];
			self.isCalledRecordEndOperation = YES;
			[self startPlayHintAudioWithIsEnd:YES];
            [_dBLevelMeterListener stopListenDBLevelMeter];
		}
@property (readwrite) NSInteger recordLengthSinceUserEnd;
@property (readwrite) NSInteger currentRecordLength;
@property (nonatomic) NSTimeInterval max_wait_speech_duration;
@property (nonatomic) BOOL isNeedVad;
// 首先设置vad库类型，vad标志和压缩标志
    [DIDIVREncoder sharedInstance].detectFlag = self.isNeedVad;
    [DIDIVREncoder sharedInstance].compressFlag = self.isNeedCompress;
else if (detectStatus == RET_NO_SPEECH)                                     //没有说话
        {
            self.mfeResult = EVoiceRecognitionClientErrorStatusNoSpeech;
            break;
        }
// 避免提示音对VAD的干扰
            if ((iPlayToneFlag & EVoiceRecognitionPlayTonesRecStart) == 0) {
                [[DIDIVREncoder sharedInstance] setParameter: PARAM_OFFSET withValue: 0];
            } else {
                [[DIDIVREncoder sharedInstance] setParameter: PARAM_OFFSET withValue: 8];
            }
nIn_Speech_Threshold = 8;

Android：public static final String EXTRA_VAD_MAX_SPEECH_END_SILENCE_LENGTH = "vad_max_speech_end_silence_length"; vad.param_9 这个参数是修改客户端VAD参数的
#define MAX_SEND_PACKETS_FOR_MUSIC_RECOG 9
EVoiceRecognitionClientErrorStatusNoSpeech、RET_NO_SPEECH
DWORD nSleep_Timeout_Init = 18;     /**< @brief Max Speech Length: 18s */
DWORD nMin_Speech_Duration_Init = 5;
#ifdef SILENCE_DETECTOR_TIME_DOMAIN	// No	
	CheckSilence();
#else
	m_sPos = nRecFrameS;
	m_ePos = m_frameNum - 1;
#endif

13.
http://qbview.url.cn/getResourceInfo?appid=31&url=http%3A%2F%2F123.125.253.3%2Fstatic%2Fvoiceindex.html%3Flat%3D..%26lng%3D..%26ticket%3D%26nsukey%3DpmVltEQbqhOPme75nVvAcOTX6XAD2kkwRi3c6G0wpm0ik4sFccD9obmIAZ6AzaMg%252Flp2F64IVy4DAYLIdA6%252BNg%253D%253D&version=10000&doview=1&ua=Mozilla%2F5.0+(Macintosh%3B+Intel+Mac+OS+X+10_11_6)+AppleWebKit%2F601.7.7+(KHTML%2C+like+Gecko)+Version%2F9.1.2+Safari%2F601.7.7&keeplink=0&reformat=0&source=app_zcsj_voiceIndex

{
    lat = "40.04373779296875";
    lng = "116.2890641276042";
    ticket = "OoL8rzjeBOsx-nxOcHUDIBK0DspA-dRGLvYD2pWt4vdMzDEOgzAMheG7vNmDrTpu7NukagtMIDIwRLk7kbLwtvcPX0NBAIQPIpmyObuLsLIQvgh9vwg_RMNRar32czRR8-Rm5p3wf_xMWIYmOfOcDnid_obgfgcAAP__";
}

http://help.xiaojukeji.com/static/index.html?&ticket=OoL8rzjeBOsx-nxOcHUDIBK0DspA-dRGLvYD2pWt4vdMzDEOgzAMheG7vNmDrTpu7NukagtMIDIwRLk7kbLwtvcPX0NBAIQPIpmyObuLsLIQvgh9vwg_RMNRar32czRR8-Rm5p3wf_xMWIYmOfOcDnid_obgfgcAAP__&lat=40.04374701605903&lng=116.2890687391493&__randNum=907758931

http://123.125.253.3/static/voiceindex.html?&ticket=OoL8rzjeBOsx-nxOcHUDIBK0DspA-dRGLvYD2pWt4vdMzDEOgzAMheG7vNmDrTpu7NukagtMIDIwRLk7kbLwtvcPX0NBAIQPIpmyObuLsLIQvgh9vwg_RMNRar32czRR8-Rm5p3wf_xMWIYmOfOcDnid_obgfgcAAP__&lat=40.04374701605903&lng=116.2890687391493&__randNum=907758931

http://123.125.253.3/static/login.html
http://123.125.253.3/static/voiceChat.html