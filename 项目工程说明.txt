1.Release是用的DIDIVoiceRecognitionClient_Publish.h；

2.ISCForOneProject项目git地址：https://git.xiaojukeji.com/zhangkaiming/ISCForOneProject，是集成中间层和ASR SDK的pod工程，不需要编译，是通过pod导入工程；

3.获取语音音量的接口：[[DIDIVoiceRecognitionClient sharedInstance] getCurrentDBLevelMeter]；

4、DiSpecialDriver项目的服务中心H5为KFOnlineWebViewController，在registBridge方法中调用录音模块，唤起KefuMsgClient类的相关接口，即@“startRecord"（[kefuClient startRecWithPid:data]）与@"endRecord"（[kefuClient finishSpeak]）；

5.[kefuClient startRecWithPid:data]中data的数据结构为
{
    chatInfo =     {
        businessType = 1;
        cell = 18800000004;
        cityId = 1;
        message = "";
        mid = "6220bd3e-f003-4a6b-8f57-64ac0b0afcdc";
        msgType = 0;
        orderId = 0;
        roleType = 3;
        skillType = common;
        source = "-1";
        traceId = "1c9a629d-d982-4139-8e43-24f143931d20";
        uid = 564069099110401;
    };
    pid = 10001;
	newVoice = 0; //1为新版0为旧版
}
凯铭，我看之前司机端把小流量的判断扔到KefuMsgClient里判断了。

6.查看.a静态库支持的CPU型号命令：lipo -info XXX.a
合并模拟器与真机的.a库，命令：
lipo -create XXX/iphoneos/XXX.a XXX/iphonesimulator/XXX.a  -output XXX/iOS/XXX.a
其中XXX/iphoneos/XXX.a为真机库，XXX/iphonesimulator/XXX.a为模拟器库，-output XXX/iOS/XXX.a为两个库合并后存放的路径
/Users/guoliting/Library/Developer/Xcode/DerivedData/DIDIKeFuClient-ftmkneqfxgutfvaxyewetiblycoc/Build/Products
lipo -create Release-iphoneos/libDIDIKeFuClient.a Release-iphonesimulator/libDIDIKeFuClient.a -output Release-iOS/libDIDIKeFuClient.a
/Users/guoliting/Library/Developer/Xcode/DerivedData/DDASRClientSample-dgsitlqlrfjkyrcxejallpopihli/Build/Products
lipo -create Release-iphoneos/libDDVoiceRecognitionClient.a Release-iphonesimulator/libDDVoiceRecognitionClient.a -output Release-iOS/libDDVoiceRecognitionClient.a
/Users/guoliting/Library/Developer/Xcode/DerivedData/SpeechSynthesizer-bmmghtjsummbczcfdoblgggyqtfn/Build/Products
lipo -create Release-iphoneos/libSpeechSynthesizer.a Release-iphonesimulator/libSpeechSynthesizer.a -output Release-iOS/libSpeechSynthesizer.a

@文彬 @Snow❄ @郑普亨 @Chelsea  @娟 儿💃 💎  https://www.pgyer.com/AutomaticSpeechRec 最新版已发布，需要测试的同学手动更新下，SDK体积缩减，功能没影响。

7.在Demo项目里增加Podfile文件，集成ISCProject库，内容如下：
使用仓库的某个tag:
target 'Waver' do
    platform:ios, '7.0'
    pod 'ISCProject', :git => "git@git.xiaojukeji.com:zhangkaiming/ISCForOneProject.git", :tag => "0.2.1"
end
使用仓库的其他分支:
target 'Waver' do
    platform:ios, '7.0'
    pod 'ISCProject', :git => "git@git.xiaojukeji.com:zhangkaiming/ISCForOneProject.git", :branch => 'develop'
end

8.集成ISCProject库后，编译报错："vtable for __cxxabiv1::__class_type_info", referenced from:
      typeinfo for CAXException in libDDVoiceRecognitionClient.a(DIDIVRDBLevelMeterListener.o)
ld: symbol(s) not found for architecture i386
clang: error: linker command failed with exit code 1 (use -v to see invocation)
解决方案：
遇到这样的问题主要是第三方库导入的配置不对，静态库中采用ObjectC++实现，因此需要您保证您工程中至少有一个.mm后缀的源文件(您可以将任意一个.m后缀的文件改名为.mm)，或者在工程属性中指定编译方式，即将Xcode的Project -> Edit Active Target -> Build -> GCC4.2 - Language -> Compile Sources As设置为"Objective-C++"

9.新版发布流程：编译好新的识别库，增加新UI后把相关头文件和.a库替换到ISCForOneProject工程，push到代码库里，司机端pod update后就可以调；

10.0719在线客服需求疑问
（1）结束录音的交互方式？
（2）录音提示音类型：
开始 iOS:record_start.caf
结束 iOS:record_end.caf
出错 iOS:record_fail.caf
附件是现有的声音文件
（3）点按录音图标到波纹的交互方式？明确H5与Native各自要实现的部分。

11.录音提示音
提示音目录：/Users/guoliting/didichuxing/asr-ios-sdk/ios-sdk/DDASRClientSample/libDDASRClient/DDASRClientResources/Tone
开启提示音：[[DIDIVoiceRecognitionClient sharedInstance] setPlayTone:EVoiceRecognitionPlayTonesRecStart isPlay:YES];
Demo使用时需要将DDASRClientResources文件夹拷贝至项目所在目录，添加至工程时打开Options只勾选Create folder reference，这样Demo运行时的App包里就会包含DDASRClientResources文件夹；

12.语音识别尾点检测
百度Android在线语音识别SDK使用方法  http://blog.csdn.net/voicefans/article/details/27345137
语音活动检测(Voice Activity Detection,VAD)又称语音端点检测,语音边界检测。
#define     PARAM_MAX_SP_DURATION       2  //控制每句之间说话的最大静音时间，单位毫秒
#define     PARAM_SPEECH_END            9  //端点检测超时，单位毫秒
[[DIDIVREncoder sharedInstance] setParameter: PARAM_MAX_SP_DURATION withValue: 2000];
    [[DIDIVREncoder sharedInstance]setParameter:PARAM_SPEECH_END withValue:35];
// DIDIVoiceRecognitionClientResources/Tone
// DDASRClientResources/Tone
static NSString *kRecordTonePath = @"DDASRClientResources/Tone/";

/var/containers/Bundle/Application/E950D322-76C8-404D-8B10-6A3F3F1261DA/DiSpecialDriver.app/DDASRClientResources/Tone/record_start.caf
/var/mobile/Containers/Data/Application/142E3545-B101-4107-A832-E24C707ED962/Documents/RecordVoice/2016_07_29_17_47_37.mp3

收到的结果：{
    "asr_param" =     {
        "err_no" = "-3003";
        error = "get result error";
        idx = 1;
        sid = "2742AADC-AED6-42D5-AAD2-D8D13551AEB2";
    };
}

13.libDDVoiceRecognitionClient.a替换为Debug版，Release版运行异常。 
Thread 4:signal SIGABRT 
Stack buffer overflow detected

static void gen_key(int num, char key[]){
    if (num < 8 || key == NULL) {
        return;
    }
    if (num != 8) {
        num = 8;
    }
    
    char magic[] = "*Xj->aSr";
    
    memset(key, 127, num);
    
    for (int i = 0; i < num; ++i) {
        
        key[i] = abs((key[i] * magic[i]))%95 + 32;
    }
    return;
}
http://123.125.253.3/static/login.html

Today we’re announcing our intention to merge Uber China with Didi Chuxing.


NSBundle *bundle = [NSBundle mainBundle];
    NSString* path = [bundle pathForResource:fileName ofType:KRecordToneFileEx inDirectory:kRecordTonePath];
    NSURL *musicUrl = [[NSURL alloc] initFileURLWithPath:path];
/var/containers/Bundle/Application/54EF45B0-7E31-4134-81C1-04B92A67BF79/DiSpecialDriver.app/DDASRClientResources/Tone/fristVoice.mp3
path:/var/containers/Bundle/Application/54EF45B0-7E31-4134-81C1-04B92A67BF79/DiSpecialDriver.app/DDASRClientResources/Tone/record_start.caf

14.测试地址
NSURL *url = [NSURL URLWithString:item.url];
//    NSURL *url = [NSURL URLWithString:@"http://123.125.253.3/static/login.html"]; //测试H5
2016-08-01 21:09:12.693 DiSpecialDriversDemo[358:40572] App Transport Security has blocked a cleartext HTTP (http://) resource load since it is insecure. Temporary exceptions can be configured via your app's Info.plist file.

15.正常结束  [[DIDIVoiceRecognitionClient sharedInstance] speakFinish];
取消 [[DIDIVoiceRecognitionClient sharedInstance] stopVoiceRecognition];
EVoiceRecognitionClientWorkStatusStart,                  // 检测到用户开始说话
晚于EVoiceRecognitionClientWorkStatusNewRecordData,          // 录音数据回调

16.路测技术点：
1）有VAD的识别情况，耗时多久？  
收音机里人声不易判断，大概都在10秒以上
噪音正常识别1-2秒
音乐播放会被判断为噪音，可以识别
2）无VAD的识别情况，耗时多久？
3）噪音情况下是否丢字，识别准确度，识别时长，网络稳定情况？
会有文字识别错误，3G下识别速度正常

1、4g网络 ：电话进入后挂掉，点击语音按钮总是提示网络异常  ios
2、电话进入未做处理，未把录制的语音结果识别出来  ios
4、4g网络，录音结束后，波纹变为一条直线，页面点击无任何反应  ios
5、4g网络 语音结束后，没有识别结果 说3条语音信息丢2条  ios

Podfile中修改
pod 'DComponent_Web', :git => "git@git.xiaojukeji.com:DriveriOS/DComponent_Web.git", :tag => '0.1.1'
pod 'ISCProject', :git => "git@git.xiaojukeji.com:zhangkaiming/ISCForOneProject.git", :branch => 'develop'
#pod 'ISCProject', :git => "git@git.xiaojukeji.com:zhangkaiming/ISCForOneProject.git", :tag => “0.3.0”

MoreViewController.m中
//    NSURL *url = [NSURL URLWithString:item.url];
    NSURL *url = [NSURL URLWithString:@"http://123.125.253.3/static/login.html"]; //测试H5
//    NSURL *url = [NSURL URLWithString:@"http://123.125.253.3/static/voiceindex.html"]; //测试H5

@文彬 @Snow❄ @郑普亨 @Chelsea  @娟 儿💃 💎  https://www.pgyer.com/AutomaticSpeechRec 最新版已发布，需要测试的同学手动更新下。

https://git.xiaojukeji.com/DriveriOS/DComponent_Web
这个是之前依赖我们组建，我拆出来了，以后你们可以依赖这个组件新建一个pod开发，以后发版就再也不依赖我们替换文件了

我把pod 'DComponent_Web', :git => "git@git.xiaojukeji.com:DriveriOS/DComponent_Web.git", :tag => '0.1.1'加到司机端的Podfile里，然后手动移除KFOnlineWebViewController类与DSWeb文件夹，这样设置就行了吧？


Undefined symbols for architecture i386:
  "_DSWebSetWebViewDidLoadCallBack", referenced from:
      -[JSBridgeInitTask run] in JSBridgeInitTask.o


离线语音合成测试的功能点：
1.离线合成引擎是否正常工作；
2.设置音量是否有效；
3.设置语速是否有效；
4.包名合法性校验是否有效；

合法的包名集合
_bundleIDs = @[@"com.xiaojukeji.DiSpecialDrivers", @"com.sdu.didi.gsui", @"com.xiaojukeji.SpecialDrivers", @"com.xiaojukeji.didi", @"com.didi.passengers", @"com.sdu.didi.psnger", @"com.xiaojukeji.DDTTSDemo"];
